#!/usr/bin/env python3
"""
Civitai LoRA æ‰¹é‡ä¸‹è½½è„šæœ¬ (ä» CSV æ–‡ä»¶è¯»å–)
ç”¨æ³•: python download_lora.py
"""

import requests
import os
import time
import csv
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==================== é…ç½® ====================
API_KEY = "f0bc823242554d8f42ccc475b5c18ebb"
# ä¸‹è½½ç›®å½•ï¼šä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œæœ¬åœ°é»˜è®¤ ./lorasï¼ŒæœåŠ¡å™¨ç”¨ /workspace/shared-models/loras
SAVE_DIR = os.getenv("LORA_SAVE_DIR",
    "/workspace/shared-models/loras" if os.path.exists("/workspace") else "./loras"
)
CSV_FILE = "pose-ai.csv"  # CSV æ–‡ä»¶è·¯å¾„
MAX_WORKERS = 3       # åŒæ—¶ä¸‹è½½æ•°é‡
RETRY_TIMES = 3       # å¤±è´¥é‡è¯•æ¬¡æ•°
TIMEOUT = 120         # è¶…æ—¶æ—¶é—´(ç§’)
# ==============================================


def load_models_from_csv(csv_path):
    """ä» CSV æ–‡ä»¶åŠ è½½æ¨¡å‹åˆ—è¡¨"""
    models = []
    seen_ids = set()

    with open(csv_path, 'r', encoding='utf-8-sig') as f:
        reader = csv.DictReader(f)
        for row in reader:
            # è·å– high_noise_lora_id
            high_id = row.get('high_noise_lora_id', '').strip()
            high_name = row.get('high_noise_lora', '').strip()

            # è·å– low_noise_lora_id
            low_id = row.get('low_noise_lora_id', '').strip()
            low_name = row.get('low_noise_lora', '').strip()

            # æ·»åŠ  high_noise_lora
            if high_id and high_id != '-' and high_id.isdigit():
                vid = int(high_id)
                if vid not in seen_ids:
                    models.append((vid, high_name or f"high_{vid}"))
                    seen_ids.add(vid)

            # æ·»åŠ  low_noise_lora
            if low_id and low_id != '-' and low_id.isdigit():
                vid = int(low_id)
                if vid not in seen_ids:
                    models.append((vid, low_name or f"low_{vid}"))
                    seen_ids.add(vid)

    return models


def format_size(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024:
            return f"{size_bytes:.1f} {unit}"
        size_bytes /= 1024
    return f"{size_bytes:.1f} TB"


def download_model(version_id, name, index, total):
    """ä¸‹è½½å•ä¸ªæ¨¡å‹"""
    # ä½¿ç”¨ CSV ä¸­å®šä¹‰çš„æ ‡å‡†åŒ–æ–‡ä»¶å
    target_filename = name  # CSV ä¸­çš„æ ‡å‡†åŒ–æ–‡ä»¶å
    target_filepath = os.path.join(SAVE_DIR, target_filename)

    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆä½¿ç”¨æ ‡å‡†åŒ–æ–‡ä»¶åï¼‰
    if os.path.exists(target_filepath):
        size = os.path.getsize(target_filepath)
        return (True, f"[{index}/{total}] â­ è·³è¿‡(å·²å­˜åœ¨): {target_filename} ({format_size(size)})")

    url = f"https://civitai.com/api/download/models/{version_id}?token={API_KEY}"

    for attempt in range(RETRY_TIMES):
        try:
            response = requests.get(url, stream=True, timeout=TIMEOUT, allow_redirects=True)

            if response.status_code == 200:
                # ç›´æ¥ä¿å­˜ä¸º CSV ä¸­å®šä¹‰çš„æ ‡å‡†åŒ–æ–‡ä»¶å
                with open(target_filepath, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)

                size = os.path.getsize(target_filepath)
                return (True, f"[{index}/{total}] âœ“ {target_filename} ({format_size(size)})")

            elif response.status_code == 404:
                return (False, f"[{index}/{total}] âœ— {name[:30]} - æ¨¡å‹ä¸å­˜åœ¨(404)")
            else:
                if attempt < RETRY_TIMES - 1:
                    time.sleep(2)
                    continue
                return (False, f"[{index}/{total}] âœ— {name[:30]} - HTTP {response.status_code}")

        except requests.exceptions.Timeout:
            if attempt < RETRY_TIMES - 1:
                time.sleep(2)
                continue
            return (False, f"[{index}/{total}] âœ— {name[:30]} - è¶…æ—¶")
        except Exception as e:
            if attempt < RETRY_TIMES - 1:
                time.sleep(2)
                continue
            return (False, f"[{index}/{total}] âœ— {name[:30]} - {str(e)[:30]}")
    
    return (False, f"[{index}/{total}] âœ— {name[:30]} - é‡è¯•å¤±è´¥")


def main():
    os.makedirs(SAVE_DIR, exist_ok=True)

    # ä» CSV åŠ è½½æ¨¡å‹åˆ—è¡¨
    print("ğŸ“‹ æ­£åœ¨ä» CSV åŠ è½½æ¨¡å‹åˆ—è¡¨...")
    models = load_models_from_csv(CSV_FILE)
    total = len(models)

    print("=" * 60)
    print("  Civitai LoRA æ‰¹é‡ä¸‹è½½å™¨ (pose-ai.csv)")
    print("=" * 60)
    print(f"  CSV æ–‡ä»¶: {CSV_FILE}")
    print(f"  æ€»è®¡: {total} ä¸ªæ¨¡å‹")
    print(f"  ä¿å­˜ç›®å½•: {os.path.abspath(SAVE_DIR)}")
    print(f"  åŒæ—¶ä¸‹è½½: {MAX_WORKERS} ä¸ª")
    print(f"  é‡è¯•æ¬¡æ•°: {RETRY_TIMES} æ¬¡")
    print("=" * 60)
    print()

    success = 0
    skipped = 0
    failed = []

    start_time = time.time()

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {
            executor.submit(download_model, vid, name, i, total): (vid, name)
            for i, (vid, name) in enumerate(models, 1)
        }

        for future in as_completed(futures):
            ok, msg = future.result()
            print(msg)
            if ok:
                if "è·³è¿‡" in msg:
                    skipped += 1
                else:
                    success += 1
            else:
                failed.append(futures[future][1])

    elapsed = time.time() - start_time

    print()
    print("=" * 60)
    print(f"  ä¸‹è½½å®Œæˆ!")
    print(f"  è€—æ—¶: {elapsed/60:.1f} åˆ†é’Ÿ")
    print(f"  æˆåŠŸ: {success} ä¸ª")
    print(f"  è·³è¿‡: {skipped} ä¸ª")
    print(f"  å¤±è´¥: {len(failed)} ä¸ª")
    print("=" * 60)

    if failed:
        print(f"\nå¤±è´¥åˆ—è¡¨ ({len(failed)} ä¸ª):")
        for name in failed:
            print(f"  - {name}")

        # ä¿å­˜å¤±è´¥åˆ—è¡¨
        with open(os.path.join(SAVE_DIR, "_failed.txt"), "w", encoding="utf-8") as f:
            f.write("\n".join(failed))
        print(f"\nå¤±è´¥åˆ—è¡¨å·²ä¿å­˜åˆ°: {SAVE_DIR}/_failed.txt")


if __name__ == "__main__":
    main()