"""
ComfyUI ä»»åŠ¡å¤„ç†å™¨
"""
import json
import time
import httpx
import os
from datetime import datetime, timezone
from loguru import logger
from httpx_retry import RetryTransport
from consumer.processors.comfyui_api import ComfyUI, create_comfyui_client

class ComfyUIProcessor:
    """ComfyUIä»»åŠ¡å¤„ç†å™¨"""
    
    def __init__(self):
        # ä¸å†é¢„å…ˆåˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œè€Œæ˜¯æ ¹æ®ä»»åŠ¡åŠ¨æ€åˆ›å»º
        self.client_cache = {}  # ç¼“å­˜ä¸åŒå·¥ä½œæµçš„å®¢æˆ·ç«¯
        
        # åˆ›å»ºå¸¦é‡è¯•åŠŸèƒ½çš„HTTPå®¢æˆ·ç«¯
        self.retry_transport = RetryTransport(
            wrapped_transport=httpx.HTTPTransport(),
            max_attempts=3,
            backoff_factor=2.0,
            status_codes={408, 429, 500, 502, 503, 504}
        )
    
    def _get_comfyui_client(self, task: dict) -> ComfyUI:
        """æ ¹æ®ä»»åŠ¡è·å–å¯¹åº”çš„ComfyUIå®¢æˆ·ç«¯"""
        workflow_name = task.get("workflow_name")
        
        if workflow_name:
            # ä½¿ç”¨å·¥ä½œæµç‰¹å®šçš„å®¢æˆ·ç«¯
            if workflow_name not in self.client_cache:
                logger.info(f"ğŸ¯ åˆ›å»ºå·¥ä½œæµ '{workflow_name}' çš„ComfyUIå®¢æˆ·ç«¯")
                self.client_cache[workflow_name] = create_comfyui_client(workflow_name=workflow_name)
            return self.client_cache[workflow_name]
        else:
            # ä½¿ç”¨é»˜è®¤å®¢æˆ·ç«¯
            if "default" not in self.client_cache:
                logger.info("ğŸ”§ åˆ›å»ºé»˜è®¤ComfyUIå®¢æˆ·ç«¯")
                comfyui_url = os.getenv('COMFYUI_URL', 'http://127.0.0.1:3002')
                if comfyui_url.startswith('http://'):
                    server_address = comfyui_url[7:]
                elif comfyui_url.startswith('https://'):
                    server_address = comfyui_url[8:]
                else:
                    server_address = comfyui_url
                self.client_cache["default"] = create_comfyui_client(server_address=server_address)
            return self.client_cache["default"]
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿è¿æ¥è¢«æ­£ç¡®å…³é—­"""
        try:
            logger.info("ğŸ”Œ å…³é—­æ‰€æœ‰ç¼“å­˜çš„ ComfyUI å®¢æˆ·ç«¯è¿æ¥")
            for workflow_name, client in self.client_cache.items():
                if client:
                    logger.debug(f"å…³é—­å®¢æˆ·ç«¯: {workflow_name}")
            self.client_cache.clear()
        except Exception as e:
            logger.error(f"å…³é—­ ComfyUI å®¢æˆ·ç«¯æ—¶å‡ºé”™: {e}")
    
    def process(self, task):
        """å¤„ç†ComfyUIä»»åŠ¡"""
        task_id = task.get("taskId")
        params = task.get("params", {})
        input_data = params.get("input_data", {})
        wf_json = input_data.get("wf_json", {})

        logger.info(f"å¼€å§‹å¤„ç†ComfyUIä»»åŠ¡: {task_id}")
        logger.debug(f"ä»»åŠ¡å‚æ•°éªŒè¯:")
        logger.debug(f"  - taskId: {task_id}")
        logger.debug(f"  - paramså­˜åœ¨: {bool(params)}")
        logger.debug(f"  - input_dataå­˜åœ¨: {bool(input_data)}")
        logger.debug(f"  - wf_jsonå­˜åœ¨: {bool(wf_json)}")

        if not task_id:
            logger.error("ä»»åŠ¡IDä¸ºç©ºï¼Œæ— æ³•å¤„ç†")
            return None

        if not wf_json:
            logger.error("å·¥ä½œæµJSONä¸ºç©ºï¼Œæ— æ³•å¤„ç†")
            self._update_task_status(task_id, "FAILED", message="å·¥ä½œæµJSONä¸ºç©º",started_at=task_started_at)
            return None

        logger.debug(f"å·¥ä½œæµJSONç»“æ„: {json.dumps(wf_json, indent=2, ensure_ascii=False)[:500]}...")

        try:
            # è®°å½•ä»»åŠ¡å¼€å§‹æ—¶é—´
            task_started_at = datetime.now(timezone.utc)

            # æ‰§è¡ŒComfyUIä»»åŠ¡å¤„ç†ï¼ˆåŒ…å«æ—©æœŸæœåŠ¡æ£€æŸ¥ï¼‰
            logger.info(f"ğŸ¯ å¼€å§‹æ‰§è¡ŒComfyUIå·¥ä½œæµ: {task_id} (å·¥ä½œæµ: {task.get('workflow_name', 'é»˜è®¤')})")
            t_gen_start = time.time()
            results = self._execute_comfyui_task(task, wf_json, task_id, task_started_at)
            execution_time = time.time() - t_gen_start

            # æ£€æŸ¥æ˜¯å¦ä¸ºæœåŠ¡ä¸å¯ç”¨
            if results == "SERVICE_UNAVAILABLE":
                logger.info(f"ğŸ“‹ ä»»åŠ¡ {task_id} å› æœåŠ¡ä¸å¯ç”¨è¢«è·³è¿‡ï¼Œä¿æŒ PENDING çŠ¶æ€")
                return None  # è¿”å› Noneï¼Œä¸æ›´æ–°ä»»åŠ¡çŠ¶æ€

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºPROCESSINGï¼ˆåªæœ‰åœ¨æœåŠ¡å¯ç”¨æ—¶æ‰æ›´æ–°ï¼‰
            logger.debug(f"æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºPROCESSING: {task_id}")
            update_success = self._update_task_status(task_id, "PROCESSING", started_at=task_started_at)
            if not update_success:
                logger.warning(f"æ›´æ–°ä»»åŠ¡å¼€å§‹çŠ¶æ€å¤±è´¥ï¼Œä½†ç»§ç»­å¤„ç†: {task_id}")

            logger.info(f"å›¾åƒç”Ÿæˆè€—æ—¶: {execution_time:.2f} ç§’")
            logger.debug(f"ğŸ¯ ComfyUIæ‰§è¡Œå®Œæˆï¼Œå¼€å§‹åˆ†æç»“æœ:")
            logger.debug(f"  - resultsç±»å‹: {type(results)}")
            logger.debug(f"  - resultså€¼: {results}")
            logger.debug(f"  - resultsæ˜¯å¦ä¸ºNone: {results is None}")
            logger.debug(f"  - resultsæ˜¯å¦ä¸ºç©ºåˆ—è¡¨: {results == []}")
            if results:
                logger.debug(f"  - resultsé•¿åº¦: {len(results)}")
                for i, result in enumerate(results):
                    logger.debug(f"  - result[{i}]: {result} (ç±»å‹: {type(result)})")

            # æ ¹æ®ç»“æœæ›´æ–°ä»»åŠ¡çŠ¶æ€
            if results and len(results) > 0:
                logger.info(f"âœ… ä»»åŠ¡æ‰§è¡ŒæˆåŠŸï¼Œç”Ÿæˆäº† {len(results)} ä¸ªç»“æœ")
                logger.debug(f"ğŸš€ å‡†å¤‡è°ƒç”¨_update_task_statusæ›´æ–°ä¸ºCOMPLETEDçŠ¶æ€")
                logger.debug(f"ğŸš€ output_dataå°†è®¾ç½®ä¸º: {{'urls': {results}}}")

                update_success = self._update_task_status(
                    task_id, "COMPLETED",
                    output_data={"urls": results},
                    started_at=task_started_at,
                    finished_at=datetime.now(timezone.utc)
                )

                if update_success:
                    logger.info(f"âœ… ä»»åŠ¡å®ŒæˆçŠ¶æ€æ›´æ–°æˆåŠŸ: {task_id}")
                else:
                    logger.error(f"âŒ æ›´æ–°ä»»åŠ¡å®ŒæˆçŠ¶æ€å¤±è´¥: {task_id}")

                logger.debug(f"ğŸ¯ è¿”å›ç»“æœ: {results}")
                return results
            else:
                logger.error(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼šæ²¡æœ‰ç”Ÿæˆä»»ä½•ç»“æœ")
                logger.error(f"âŒ è¯¦ç»†ä¿¡æ¯ - resultsç±»å‹: {type(results)}, resultså€¼: {results}")
                logger.debug(f"ğŸš€ å‡†å¤‡è°ƒç”¨_update_task_statusæ›´æ–°ä¸ºFAILEDçŠ¶æ€")

                update_success = self._update_task_status(
                    task_id, "FAILED",
                    message="No results generated.",
                    started_at=task_started_at,
                    finished_at=datetime.now(timezone.utc)
                )

                if update_success:
                    logger.info(f"âœ… ä»»åŠ¡å¤±è´¥çŠ¶æ€æ›´æ–°æˆåŠŸ: {task_id}")
                else:
                    logger.error(f"âŒ æ›´æ–°ä»»åŠ¡å¤±è´¥çŠ¶æ€å¤±è´¥: {task_id}")

                return None

        except Exception as e:
            logger.error(f"å¤„ç†ä»»åŠ¡æ—¶å‘ç”Ÿå¼‚å¸¸: {task_id}")
            logger.error(f"å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            logger.error(f"å¼‚å¸¸æ¶ˆæ¯: {str(e)}")
            logger.error(f"å¼‚å¸¸è¯¦æƒ…:", exc_info=True)

            try:
                update_success = self._update_task_status(
                    task_id, "FAILED",
                    message=str(e),
                    started_at=task_started_at,
                    finished_at=datetime.now(timezone.utc)
                )
                if not update_success:
                    logger.error(f"æ›´æ–°ä»»åŠ¡å¼‚å¸¸çŠ¶æ€å¤±è´¥: {task_id}")
            except Exception as update_error:
                logger.error(f"æ›´æ–°ä»»åŠ¡çŠ¶æ€æ—¶ä¹Ÿå‘ç”Ÿå¼‚å¸¸: {str(update_error)}")

            return None



    def _execute_comfyui_task(self, task, wf_json, task_id, task_started_at):
        """æ‰§è¡ŒComfyUIä»»åŠ¡"""
        workflow_name = task.get("workflowName", "é»˜è®¤")
        environment = task.get("environment", "comm")
        target_port = task.get("target_port", 3001)
        
        logger.debug(f"ğŸ¯ å¼€å§‹æ‰§è¡ŒComfyUIå·¥ä½œæµ: {task_id}")
        logger.debug(f"  - å·¥ä½œæµ: {workflow_name}")
        logger.debug(f"  - ç¯å¢ƒ: {environment}")
        logger.debug(f"  - ç«¯å£: {target_port}")

        try:
            # æ ¹æ®ä»»åŠ¡è·å–å¯¹åº”çš„ComfyUIå®¢æˆ·ç«¯
            comfyui = self._get_comfyui_client(task)
            
            # æ—©æœŸæ£€æŸ¥ï¼šéªŒè¯ ComfyUI æœåŠ¡æ˜¯å¦å¯ç”¨
            logger.debug(f"ğŸ” æ£€æŸ¥ ComfyUI æœåŠ¡å¯ç”¨æ€§: {comfyui.server_address}")
            if not comfyui.check_server_health():
                logger.warning(f"âš ï¸  ComfyUI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {comfyui.server_address}")
                logger.info(f"ğŸ“‹ è·³è¿‡ä»»åŠ¡ {task_id}ï¼Œç­‰å¾…æœåŠ¡æ¢å¤")
                return "SERVICE_UNAVAILABLE"  # è¿”å›ç‰¹æ®Šå€¼è¡¨ç¤ºæœåŠ¡ä¸å¯ç”¨
            
            logger.debug(f"âœ… ComfyUI æœåŠ¡å¯ç”¨ï¼Œç»§ç»­å¤„ç†ä»»åŠ¡")
            logger.debug(f"ğŸ”— ä½¿ç”¨ComfyUIå®¢æˆ·ç«¯ï¼Œè¿æ¥å¤ç”¨æ¬¡æ•°: {comfyui.connection_reuse_count}")

            logger.info(f"ğŸš€ å¼€å§‹ç”Ÿæˆå›¾åƒ (ç¯å¢ƒ: {environment}, ç«¯å£: {target_port})...")
            logger.debug(f"ğŸ¯ è°ƒç”¨comfyui.get_imagesï¼Œå‚æ•°:")
            logger.debug(f"  - wf_jsonç±»å‹: {type(wf_json)}")
            logger.debug(f"  - task_id: {task_id}")

            # é¢„å¤„ç†å·¥ä½œæµ
            wf_json = self._preprocess_workflow(wf_json)

            # åˆ›å»ºç®€å•çš„è¿›åº¦å›è°ƒå‡½æ•°
            def progress_callback(task_id, status, message):
                self._update_task_status(task_id, status, message, started_at=task_started_at)

            results = comfyui.get_images(wf_json, task_id, task_id=task_id, progress_callback=progress_callback)

            logger.debug(f"ğŸ¯ ComfyUI APIè¿”å›ç»“æœåˆ†æ:")
            logger.debug(f"  - resultsç±»å‹: {type(results)}")
            logger.debug(f"  - resultså€¼: {results}")
            logger.debug(f"  - resultsæ˜¯å¦ä¸ºNone: {results is None}")
            logger.debug(f"  - resultsæ˜¯å¦ä¸ºç©º: {not results}")
            if results:
                logger.debug(f"  - resultsé•¿åº¦: {len(results)}")
                logger.debug(f"  - resultså†…å®¹è¯¦ç»†:")
                for i, url in enumerate(results):
                    logger.debug(f"    [{i}]: {url} (ç±»å‹: {type(url)})")
            else:
                logger.debug(f"  - resultsä¸ºç©ºæˆ–Noneï¼Œæ— æ³•ç”Ÿæˆå›¾åƒ")

            logger.debug(f"ğŸ¯ _execute_comfyui_taskå³å°†è¿”å›: {results}")
            return results

        except ImportError as e:
            logger.error(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {str(e)}")
            raise
        except ConnectionRefusedError as e:
            # è¿æ¥è¢«æ‹’ç»ï¼Œè¯´æ˜æœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡ä»»åŠ¡
            logger.warning(f"âš ï¸  ComfyUI è¿æ¥è¢«æ‹’ç»: {str(e)}")
            logger.info(f"ğŸ“‹ è·³è¿‡ä»»åŠ¡ {task_id}ï¼Œç­‰å¾…æœåŠ¡æ¢å¤")
            return "SERVICE_UNAVAILABLE"
        except Exception as e:
            logger.error(f"æ‰§è¡ŒComfyUIä»»åŠ¡æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
            logger.error(f"å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            logger.debug(f"å¼‚å¸¸è¯¦æƒ…:", exc_info=True)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºè¿æ¥ç›¸å…³é”™è¯¯
            error_msg = str(e).lower()
            if any(keyword in error_msg for keyword in ["connection", "websocket", "refused", "timeout", "not available"]):
                logger.warning(f"âš ï¸  æ£€æµ‹åˆ°è¿æ¥é”™è¯¯: {str(e)}")
                logger.info(f"ğŸ“‹ è·³è¿‡ä»»åŠ¡ {task_id}ï¼Œç­‰å¾…æœåŠ¡æ¢å¤")
                # æ¸…ç†å®¢æˆ·ç«¯ç¼“å­˜ï¼Œä¸‹æ¬¡é‡æ–°åˆ›å»º
                workflow_name = task.get("workflow_name")
                cache_key = workflow_name if workflow_name else "default"
                if cache_key in self.client_cache:
                    self.client_cache.pop(cache_key)
                return "SERVICE_UNAVAILABLE"
            
            # å…¶ä»–å¼‚å¸¸ç»§ç»­æŠ›å‡ºï¼Œå°†è¢«æ ‡è®°ä¸º FAILED
            raise
    
    def _preprocess_workflow(self, wf_json):
        """é¢„å¤„ç†å·¥ä½œæµ"""
        from services.media_service import media_service
        from services.node_service import node_service

        logger.debug(f"å¼€å§‹é¢„å¤„ç†å·¥ä½œæµ")
        logger.debug(f"å·¥ä½œæµåŒ…å« {len(wf_json)} ä¸ªèŠ‚ç‚¹")

        # ä½¿ç”¨èŠ‚ç‚¹å¤„ç†å™¨æ³¨å†Œè¡¨æ”¶é›†è¿œç¨‹URL
        logger.debug(f"å¼€å§‹æ”¶é›†è¿œç¨‹URL")
        remote_urls, url_to_node_mapping = node_service.collect_remote_urls(wf_json)
        logger.debug(f"æ”¶é›†åˆ° {len(remote_urls)} ä¸ªè¿œç¨‹URL")
        
        # å¦‚æœæœ‰è¿œç¨‹èµ„æºï¼Œä½¿ç”¨å¼‚æ­¥æ‰¹é‡ä¸‹è½½
        if remote_urls:
            logger.info(f"å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(remote_urls)} ä¸ªè¿œç¨‹èµ„æº")
            logger.debug(f"è¿œç¨‹èµ„æºURLåˆ—è¡¨: {remote_urls}")
            logger.debug(f"URLåˆ°èŠ‚ç‚¹çš„æ˜ å°„å…³ç³»: {url_to_node_mapping}")
            
            try:
                # ä½¿ç”¨åª’ä½“æœåŠ¡æ‰¹é‡ä¸‹è½½ï¼ˆæ”¯æŒå›¾ç‰‡å’ŒéŸ³é¢‘ï¼‰
                logger.debug(f"è°ƒç”¨ media_service.download_media_batch_sync å¼€å§‹ä¸‹è½½")
                download_results = media_service.download_media_batch_sync(remote_urls)
                logger.debug(f"ä¸‹è½½å®Œæˆï¼Œç»“æœ: {download_results}")
                logger.info(f"æˆåŠŸä¸‹è½½ {len(download_results)} ä¸ªèµ„æº")
                
                # ä½¿ç”¨æ³¨å†Œè¡¨æ›´æ–°å·¥ä½œæµè·¯å¾„
                logger.debug(f"å¼€å§‹æ›´æ–°å·¥ä½œæµä¸­çš„è·¯å¾„")
                node_service.update_workflow_paths(wf_json, download_results, url_to_node_mapping)
                logger.debug(f"å·¥ä½œæµè·¯å¾„æ›´æ–°å®Œæˆ")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹è½½å¤±è´¥çš„èµ„æº
                failed_urls = set(remote_urls) - set(download_results.keys())
                if failed_urls:
                    failed_urls_str = ', '.join(failed_urls)
                    logger.error(f"âŒ ä»¥ä¸‹èµ„æºä¸‹è½½å¤±è´¥: {failed_urls_str}")
                    raise Exception(f"é¢„å¤„ç†å·¥ä½œæµå¤±è´¥ï¼šæ— æ³•ä¸‹è½½èµ„æº {failed_urls_str}")
                else:
                    logger.debug(f"æ‰€æœ‰èµ„æºä¸‹è½½æˆåŠŸ")
                    
            except Exception as e:
                logger.error(f"âŒ æ‰¹é‡ä¸‹è½½èµ„æºå¤±è´¥: {str(e)}")
                raise Exception(f"é¢„å¤„ç†å·¥ä½œæµå¤±è´¥ï¼š{str(e)}")

        logger.debug(f"é¢„å¤„ç†å®Œæˆ")
        return wf_json



    def _update_task_status(self, task_id, status, message=None,
                           started_at=None, finished_at=None, output_data=None):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        from config.settings import task_api_url

        # è¯¦ç»†è°ƒè¯•ä¿¡æ¯
        logger.debug(f"ğŸ”„ _update_task_status è¢«è°ƒç”¨:")
        logger.debug(f"  - task_id: {task_id}")
        logger.debug(f"  - status: {status}")
        logger.debug(f"  - message: {message}")
        logger.debug(f"  - started_at: {started_at}")
        logger.debug(f"  - finished_at: {finished_at}")
        logger.debug(f"  - output_data: {output_data}")
        logger.debug(f"  - output_dataç±»å‹: {type(output_data)}")
        if output_data:
            logger.debug(f"  - output_dataè¯¦ç»†å†…å®¹: {json.dumps(output_data, indent=2, ensure_ascii=False)}")

        url = f"{task_api_url}/api/comm/task/update"
        logger.debug(f"  - ç›®æ ‡URL: {url}")

        payload = {
            "taskId": task_id,
            "status": status,
            "started_at":started_at
        }

        if message:
            payload["task_message"] = message
            logger.debug(f"  - æ·»åŠ messageåˆ°payload: {message}")
        if started_at:
            formatted_started_at = started_at.strftime("%Y-%m-%d %H:%M:%S") if isinstance(started_at, datetime) else started_at
            payload["started_at"] = formatted_started_at
            logger.debug(f"  - æ·»åŠ started_atåˆ°payload: {formatted_started_at}")
        if finished_at:
            formatted_finished_at = finished_at.strftime("%Y-%m-%d %H:%M:%S") if isinstance(finished_at, datetime) else finished_at
            payload["finished_at"] = formatted_finished_at
            logger.debug(f"  - æ·»åŠ finished_atåˆ°payload: {formatted_finished_at}")
        if output_data:
            payload["output_data"] = output_data
            logger.debug(f"  - æ·»åŠ output_dataåˆ°payload: {output_data}")

        logger.debug(f"  - æœ€ç»ˆpayload: {json.dumps(payload, indent=2, ensure_ascii=False)}")

        try:
            t_start = time.time()
            logger.debug(f"ğŸ“¤ å‘é€POSTè¯·æ±‚åˆ°: {url}")
            
            with httpx.Client(transport=self.retry_transport, timeout=30.0) as client:
                response = client.post(url, json=payload)
                logger.debug(f"ğŸ“¥ æ”¶åˆ°å“åº”çŠ¶æ€ç : {response.status_code}")
                logger.debug(f"ğŸ“¥ å“åº”å¤´: {dict(response.headers)}")
                
                try:
                    response_text = response.text
                    logger.debug(f"ğŸ“¥ å“åº”å†…å®¹: {response_text}")
                except Exception as text_error:
                    logger.debug(f"ğŸ“¥ æ— æ³•è¯»å–å“åº”å†…å®¹: {text_error}")
                
                response.raise_for_status()
                
                # å¤„ç†æ–°çš„ API å“åº”æ ¼å¼
                response_data = response.json()
                code = response_data.get("code")
                api_message = response_data.get("message", "")
                success = response_data.get("success", code == 200)
                
                if not success:
                    logger.error(f"âŒ APIè¿”å›é”™è¯¯ for task {task_id}: code={code}, message={api_message}")
                    return False
                    
                logger.info(f"âœ… Task update sent successfully for task {task_id}, è€—æ—¶{time.time() - t_start:.2f}ç§’")
                logger.debug(f"âœ… æˆåŠŸå‘é€ä»»åŠ¡çŠ¶æ€æ›´æ–°: {status}")
                return True
                
        except httpx.HTTPError as e:
            logger.error(f"âŒ HTTPè¯·æ±‚å¤±è´¥ for task {task_id}: {str(e)}")
            logger.error(f"âŒ è¯·æ±‚URL: {url}")
            logger.error(f"âŒ è¯·æ±‚payload: {payload}")
            if hasattr(e, 'response') and e.response is not None:
                logger.error(f"âŒ å“åº”çŠ¶æ€ç : {e.response.status_code}")
                try:
                    logger.error(f"âŒ å“åº”å†…å®¹: {e.response.text}")
                except:
                    logger.error(f"âŒ æ— æ³•è¯»å–é”™è¯¯å“åº”å†…å®¹")
            return False
        except Exception as e:
            logger.error(f"âŒ å‘é€ä»»åŠ¡çŠ¶æ€æ›´æ–°æ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸ for task {task_id}: {str(e)}")
            logger.error(f"âŒ å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            logger.debug(f"âŒ å¼‚å¸¸è¯¦æƒ…:", exc_info=True)
            return False
