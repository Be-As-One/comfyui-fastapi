"""
å­˜å‚¨å·¥å…· - æ”¯æŒå¤šç§äº‘å­˜å‚¨æä¾›å•†
"""
import os
import base64
from abc import ABC, abstractmethod
from io import BytesIO
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
from loguru import logger
from config.settings import bucket_name

class StorageProvider(ABC):
    """å­˜å‚¨æä¾›å•†æŠ½è±¡åŸºç±»"""

    @abstractmethod
    def upload_file(self, source_file_name: str, destination_path: str) -> str:
        """ä¸Šä¼ æ–‡ä»¶ï¼Œè¿”å›URL"""
        pass

    @abstractmethod
    def upload_binary(self, binary_data: bytes, destination_path: str) -> str:
        """ä¸Šä¼ äºŒè¿›åˆ¶æ•°æ®ï¼Œè¿”å›URL"""
        pass

    @abstractmethod
    def upload_base64(self, base64_data: str, destination_path: str) -> str:
        """ä¸Šä¼ base64æ•°æ®ï¼Œè¿”å›URL"""
        pass

class GCSProvider(StorageProvider):
    """Google Cloud Storage æä¾›å•†"""

    def __init__(self, bucket_name: str):
        try:
            from google.cloud import storage
            self.client = storage.Client()
            self.bucket = self.client.bucket(bucket_name)
            self.bucket_name = bucket_name
        except ImportError:
            raise ImportError("google-cloud-storage is required for GCS provider")

    def upload_file(self, source_file_name: str, destination_path: str) -> str:
        """ä¸Šä¼ æ–‡ä»¶åˆ°GCS"""
        try:
            blob = self.bucket.blob(destination_path)
            blob.upload_from_filename(source_file_name)
            logger.info(f"File {source_file_name} uploaded to GCS: {destination_path}")

            # åˆ é™¤æœ¬åœ°æ–‡ä»¶
            os.remove(source_file_name)
            logger.info(f"Local file {source_file_name} deleted after upload")

            return f"https://storage.googleapis.com/{self.bucket_name}/{destination_path}"
        except Exception as e:
            logger.error(f"Failed to upload file to GCS: {e}")
            raise

    def upload_binary(self, binary_data: bytes, destination_path: str) -> str:
        """ä¸Šä¼ äºŒè¿›åˆ¶æ•°æ®åˆ°GCS"""
        logger.info(f"å¼€å§‹ä¸Šä¼ äºŒè¿›åˆ¶æ•°æ®åˆ°GCS: {destination_path}")
        logger.debug(f"æ•°æ®å¤§å°: {len(binary_data)} bytes")

        try:
            blob = self.bucket.blob(destination_path)
            logger.debug(f"åˆ›å»ºGCS blobå¯¹è±¡: {destination_path}")

            blob.upload_from_string(binary_data)
            logger.debug(f"æ•°æ®ä¸Šä¼ å®Œæˆ")

            url = f"https://storage.googleapis.com/{self.bucket_name}/{destination_path}"
            logger.info(f"GCSä¸Šä¼ æˆåŠŸ: {url}")
            return url
        except Exception as e:
            logger.error(f"GCSä¸Šä¼ å¤±è´¥: {str(e)}")
            logger.error(f"å¤±è´¥è¯¦æƒ… - è·¯å¾„: {destination_path}, æ•°æ®å¤§å°: {len(binary_data)} bytes")
            raise

    def upload_base64(self, base64_data: str, destination_path: str) -> str:
        """ä¸Šä¼ base64æ•°æ®åˆ°GCS"""
        try:
            file_data = base64.b64decode(base64_data)
            file_obj = BytesIO(file_data)

            blob = self.bucket.blob(destination_path)
            blob.upload_from_file(file_obj, content_type='application/octet-stream')
            blob.make_public()

            url = blob.public_url
            logger.info(f"Base64 data uploaded to GCS: {url}")
            return url
        except Exception as e:
            logger.error(f"Failed to upload base64 data to GCS: {e}")
            raise

class CloudflareR2Provider(StorageProvider):
    """Cloudflare R2 å­˜å‚¨æä¾›å•†"""

    def __init__(self, bucket_name: str, account_id: str, access_key: str, secret_key: str, public_domain: str = None):
        try:
            import boto3
            self.s3_client = boto3.client(
                's3',
                endpoint_url=f'https://{account_id}.r2.cloudflarestorage.com',
                aws_access_key_id=access_key,
                aws_secret_access_key=secret_key,
                region_name='auto'
            )
            self.bucket_name = bucket_name
            self.public_domain = public_domain or f"https://pub-{account_id}.r2.dev"
        except ImportError:
            raise ImportError("boto3 is required for Cloudflare R2 provider")

    def upload_file(self, source_file_name: str, destination_path: str) -> str:
        """ä¸Šä¼ æ–‡ä»¶åˆ°Cloudflare R2"""
        try:
            self.s3_client.upload_file(source_file_name, self.bucket_name, destination_path)
            logger.info(f"File {source_file_name} uploaded to R2: {destination_path}")

            # åˆ é™¤æœ¬åœ°æ–‡ä»¶
            os.remove(source_file_name)
            logger.info(f"Local file {source_file_name} deleted after upload")

            return f"{self.public_domain}/{destination_path}"
        except Exception as e:
            logger.error(f"Failed to upload file to R2: {e}")
            raise

    def upload_binary(self, binary_data: bytes, destination_path: str) -> str:
        """ä¸Šä¼ äºŒè¿›åˆ¶æ•°æ®åˆ°Cloudflare R2"""
        logger.info(f"å¼€å§‹ä¸Šä¼ äºŒè¿›åˆ¶æ•°æ®åˆ°R2: {destination_path}")
        logger.debug(f"æ•°æ®å¤§å°: {len(binary_data)} bytes")

        try:
            self.s3_client.put_object(
                Bucket=self.bucket_name,
                Key=destination_path,
                Body=binary_data
            )
            logger.debug(f"R2ä¸Šä¼ å®Œæˆ")

            url = f"{self.public_domain}/{destination_path}"
            logger.info(f"R2ä¸Šä¼ æˆåŠŸ: {url}")
            return url
        except Exception as e:
            logger.error(f"R2ä¸Šä¼ å¤±è´¥: {str(e)}")
            logger.error(f"å¤±è´¥è¯¦æƒ… - è·¯å¾„: {destination_path}, æ•°æ®å¤§å°: {len(binary_data)} bytes")
            raise

    def upload_base64(self, base64_data: str, destination_path: str) -> str:
        """ä¸Šä¼ base64æ•°æ®åˆ°Cloudflare R2"""
        try:
            file_data = base64.b64decode(base64_data)
            return self.upload_binary(file_data, destination_path)
        except Exception as e:
            logger.error(f"Failed to upload base64 data to R2: {e}")
            raise

class StorageManager:
    """å­˜å‚¨ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†å¤šç§å­˜å‚¨æä¾›å•†"""

    def __init__(self):
        self.providers = {}
        self.default_provider = None
        self.executor = ThreadPoolExecutor(max_workers=4)
        self._initialized = False

    def register_provider(self, name: str, provider: StorageProvider, is_default: bool = False):
        """æ³¨å†Œå­˜å‚¨æä¾›å•†"""
        self.providers[name] = provider
        if is_default or self.default_provider is None:
            self.default_provider = name
        logger.info(f"ğŸ“¦ æ³¨å†Œå­˜å‚¨æä¾›å•†: {name}")

    def get_provider(self, name: str = None) -> StorageProvider:
        """è·å–å­˜å‚¨æä¾›å•†"""
        provider_name = name or self.default_provider
        if provider_name not in self.providers:
            raise ValueError(f"Storage provider '{provider_name}' not found")
        return self.providers[provider_name]

    def upload_file(self, source_file_name: str, destination_path: str, provider: str = None) -> str:
        """ä¸Šä¼ æ–‡ä»¶"""
        return self.get_provider(provider).upload_file(source_file_name, destination_path)

    def upload_binary(self, binary_data: bytes, destination_path: str, provider: str = None) -> str:
        """ä¸Šä¼ äºŒè¿›åˆ¶æ•°æ®"""
        # æ£€æŸ¥æ˜¯å¦å·²åˆå§‹åŒ–
        if not self.is_initialized():
            raise RuntimeError("å­˜å‚¨ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ initialize() æ–¹æ³•")

        provider_name = provider or self.default_provider
        logger.info(f"ä½¿ç”¨å­˜å‚¨æä¾›å•†ä¸Šä¼ : {provider_name}")
        logger.debug(f"ä¸Šä¼ è·¯å¾„: {destination_path}, æ•°æ®å¤§å°: {len(binary_data)} bytes")

        try:
            result = self.get_provider(provider).upload_binary(binary_data, destination_path)
            logger.info(f"å­˜å‚¨ç®¡ç†å™¨ä¸Šä¼ æˆåŠŸ: {result}")
            return result
        except Exception as e:
            logger.error(f"å­˜å‚¨ç®¡ç†å™¨ä¸Šä¼ å¤±è´¥: {str(e)}")
            logger.error(f"æä¾›å•†: {provider_name}, è·¯å¾„: {destination_path}")
            raise

    def upload_base64(self, base64_data: str, destination_path: str, provider: str = None) -> str:
        """ä¸Šä¼ base64æ•°æ®"""
        return self.get_provider(provider).upload_base64(base64_data, destination_path)

    def upload_file_async(self, source_file_name: str, destination_path: str, provider: str = None):
        """å¼‚æ­¥ä¸Šä¼ æ–‡ä»¶"""
        future = self.executor.submit(self.upload_file, source_file_name, destination_path, provider)
        return future

    def upload_binary_async(self, binary_data: bytes, destination_path: str, provider: str = None):
        """å¼‚æ­¥ä¸Šä¼ äºŒè¿›åˆ¶æ•°æ®"""
        future = self.executor.submit(self.upload_binary, binary_data, destination_path, provider)
        return future

    def initialize(self):
        """åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨ï¼Œé…ç½®æ‰€æœ‰å¯ç”¨çš„å­˜å‚¨æä¾›å•†"""
        if self._initialized:
            logger.debug("å­˜å‚¨ç®¡ç†å™¨å·²ç»åˆå§‹åŒ–ï¼Œè·³è¿‡")
            return

        logger.info("ğŸ”§ å¼€å§‹åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨...")

        # æ¸…ç©ºç°æœ‰æä¾›å•†
        self.providers.clear()
        self.default_provider = None

        # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
        storage_provider = os.getenv('STORAGE_PROVIDER', 'gcs')
        logger.debug(f"é…ç½®çš„å­˜å‚¨æä¾›å•†: {storage_provider}")

        # å°è¯•é…ç½®GCS
        if storage_provider == 'gcs' or os.getenv('GCS_BUCKET_NAME'):
            try:
                gcs_bucket = os.getenv('GCS_BUCKET_NAME', bucket_name)
                if gcs_bucket:
                    logger.debug(f"é…ç½® GCS bucket: {gcs_bucket}")
                    gcs_provider = GCSProvider(gcs_bucket)
                    self.register_provider('gcs', gcs_provider, is_default=(storage_provider == 'gcs'))
                    logger.info("âœ… GCS provider configured")
            except ImportError:
                logger.warning("âš ï¸ google-cloud-storage not installed, skipping GCS provider")
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to configure GCS provider: {e}")

        # å°è¯•é…ç½®Cloudflare R2
        if storage_provider == 'r2' or os.getenv('R2_BUCKET_NAME'):
            try:
                r2_bucket = os.getenv('R2_BUCKET_NAME')
                r2_account_id = os.getenv('R2_ACCOUNT_ID')
                r2_access_key = os.getenv('R2_ACCESS_KEY')
                r2_secret_key = os.getenv('R2_SECRET_KEY')
                r2_public_domain = os.getenv('R2_PUBLIC_DOMAIN')

                if all([r2_bucket, r2_account_id, r2_access_key, r2_secret_key]):
                    logger.debug(f"é…ç½® R2 bucket: {r2_bucket}")
                    r2_provider = CloudflareR2Provider(
                        bucket_name=r2_bucket,
                        account_id=r2_account_id,
                        access_key=r2_access_key,
                        secret_key=r2_secret_key,
                        public_domain=r2_public_domain
                    )
                    self.register_provider('r2', r2_provider, is_default=(storage_provider == 'r2'))
                    logger.info("âœ… Cloudflare R2 provider configured")
                else:
                    logger.warning("âš ï¸ R2 configuration incomplete, skipping R2 provider")
            except ImportError:
                logger.warning("âš ï¸ boto3 not installed, skipping R2 provider")
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to configure R2 provider: {e}")

        if not self.providers:
            logger.warning("âš ï¸ No storage providers configured, file uploads will be disabled")
        else:
            logger.info(f"ğŸ“¦ Storage manager initialized with providers: {list(self.providers.keys())}")
            logger.info(f"ğŸ“¦ Default provider: {self.default_provider}")

        self._initialized = True
        logger.info("âœ… å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def is_initialized(self) -> bool:
        """æ£€æŸ¥å­˜å‚¨ç®¡ç†å™¨æ˜¯å¦å·²åˆå§‹åŒ–"""
        return self._initialized and bool(self.providers)

def create_storage_manager() -> StorageManager:
    """åˆ›å»ºå¹¶é…ç½®å­˜å‚¨ç®¡ç†å™¨"""
    manager = StorageManager()

    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    storage_provider = os.getenv('STORAGE_PROVIDER', 'gcs')

    # å°è¯•é…ç½®GCS
    if storage_provider == 'gcs' or os.getenv('GCS_BUCKET_NAME'):
        try:
            gcs_bucket = os.getenv('GCS_BUCKET_NAME', bucket_name)
            if gcs_bucket:
                gcs_provider = GCSProvider(gcs_bucket)
                manager.register_provider('gcs', gcs_provider, is_default=(storage_provider == 'gcs'))
                logger.info("âœ… GCS provider configured")
        except ImportError:
            logger.warning("âš ï¸ google-cloud-storage not installed, skipping GCS provider")
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to configure GCS provider: {e}")

    # å°è¯•é…ç½®Cloudflare R2
    if storage_provider == 'r2' or os.getenv('R2_BUCKET_NAME'):
        try:
            r2_bucket = os.getenv('R2_BUCKET_NAME')
            r2_account_id = os.getenv('R2_ACCOUNT_ID')
            r2_access_key = os.getenv('R2_ACCESS_KEY')
            r2_secret_key = os.getenv('R2_SECRET_KEY')
            r2_public_domain = os.getenv('R2_PUBLIC_DOMAIN')

            if all([r2_bucket, r2_account_id, r2_access_key, r2_secret_key]):
                r2_provider = CloudflareR2Provider(
                    bucket_name=r2_bucket,
                    account_id=r2_account_id,
                    access_key=r2_access_key,
                    secret_key=r2_secret_key,
                    public_domain=r2_public_domain
                )
                manager.register_provider('r2', r2_provider, is_default=(storage_provider == 'r2'))
                logger.info("âœ… Cloudflare R2 provider configured")
            else:
                logger.warning("âš ï¸ R2 configuration incomplete, skipping R2 provider")
        except ImportError:
            logger.warning("âš ï¸ boto3 not installed, skipping R2 provider")
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to configure R2 provider: {e}")

    if not manager.providers:
        logger.warning("âš ï¸ No storage providers configured, file uploads will be disabled")
    else:
        logger.info(f"ğŸ“¦ Storage manager initialized with providers: {list(manager.providers.keys())}")

    return manager

# å…¨å±€å­˜å‚¨ç®¡ç†å™¨å®ä¾‹å˜é‡
_global_storage_manager = None

def get_storage_manager() -> StorageManager:
    """è·å–å…¨å±€å­˜å‚¨ç®¡ç†å™¨å®ä¾‹"""
    global _global_storage_manager
    if _global_storage_manager is None:
        raise RuntimeError("å­˜å‚¨ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ set_storage_manager() è®¾ç½®å®ä¾‹")
    return _global_storage_manager

def set_storage_manager(manager: StorageManager):
    """è®¾ç½®å…¨å±€å­˜å‚¨ç®¡ç†å™¨å®ä¾‹"""
    global _global_storage_manager
    _global_storage_manager = manager

def initialize_storage():
    """åˆå§‹åŒ–å…¨å±€å­˜å‚¨ç®¡ç†å™¨"""
    manager = StorageManager()
    manager.initialize()
    set_storage_manager(manager)
    return manager

# å‘åå…¼å®¹çš„æ¥å£
def upload_binary_image(binary_data: bytes, destination_path: str) -> str:
    """å‘åå…¼å®¹ï¼šä¸Šä¼ äºŒè¿›åˆ¶å›¾ç‰‡"""
    return get_storage_manager().upload_binary(binary_data, destination_path)
